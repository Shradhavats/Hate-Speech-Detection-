{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb404501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdff11a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"twitter_data.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a405e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet                 labels  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language  \n"
     ]
    }
   ],
   "source": [
    "data[\"labels\"] = data[\"class\"].map({0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"No Hate and Offensive\"})\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05cc72ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet                 labels\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  No Hate and Offensive\n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...     Offensive Language\n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...     Offensive Language\n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...     Offensive Language\n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...     Offensive Language\n"
     ]
    }
   ],
   "source": [
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "214b9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6113c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet                 labels\n",
      "0   rt mayasolov woman shouldnt complain clean ho...  No Hate and Offensive\n",
      "1   rt  boy dat coldtyga dwn bad cuffin dat hoe  ...     Offensive Language\n",
      "2   rt urkindofbrand dawg rt  ever fuck bitch sta...     Offensive Language\n",
      "3             rt cganderson vivabas look like tranni     Offensive Language\n",
      "4   rt shenikarobert shit hear might true might f...     Offensive Language\n"
     ]
    }
   ],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(clean)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5086e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data[\"tweet\"])\n",
    "y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f29e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87651302115173"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1d42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hate_speech_detection():\n",
    "    import streamlit as st\n",
    "    st.title(\"Hate Speech Detection\")\n",
    "    user = st.text_area(\"Enter any Tweet: \")\n",
    "    if len(user) < 1:\n",
    "        st.write(\"  \")\n",
    "    else:\n",
    "        sample = user\n",
    "        data = cv.transform([sample]).toarray()\n",
    "        a = clf.predict(data)\n",
    "        st.title(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2194126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hate Speech']\n"
     ]
    }
   ],
   "source": [
    "test_data=\"I will kill you \"\n",
    "df=cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a94491d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No Hate and Offensive']\n"
     ]
    }
   ],
   "source": [
    "test_data=\"you are awesome \"\n",
    "df=cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3d5e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Offensive Language']\n"
     ]
    }
   ],
   "source": [
    "test_data=\"you are bad and i don't like you \"\n",
    "df=cv.transform([test_data]).toarray()\n",
    "print(clf.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94296626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
